{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Piano MIDI Generation - Data Preprocessing\n",
        "\n",
        "This notebook handles preprocessing of the ARIA MIDI dataset for training a transformer model.\n",
        "\n",
        "## Overview\n",
        "\n",
        "1. **Load and analyze metadata** - Understand field coverage\n",
        "2. **Load MIDI files** - Read and parse MIDI data\n",
        "3. **Convert MIDI to tokens** - Tokenize MIDI events\n",
        "4. **Combine with metadata** - Create full training sequences\n",
        "5. **Save processed data** - Prepare for training\n",
        "\n",
        "## Dataset Structure\n",
        "\n",
        "- Metadata: `aria-midi-v1-deduped-ext/metadata.json`\n",
        "- MIDI files: `aria-midi-v1-deduped-ext/data/{aa-zz}/*.mid`\n",
        "- File naming: `{ID}_{audio_index}.mid` (e.g., `000002_0.mid`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mido in c:\\users\\vikas gari\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.3.3)\n",
            "Requirement already satisfied: pretty_midi in c:\\users\\vikas gari\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.2.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vikas gari\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\vikas gari\\appdata\\roaming\\python\\python313\\site-packages (from mido) (25.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in c:\\users\\vikas gari\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pretty_midi) (2.3.4)\n",
            "Requirement already satisfied: six in c:\\users\\vikas gari\\appdata\\roaming\\python\\python313\\site-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: importlib_resources in c:\\users\\vikas gari\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pretty_midi) (6.5.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\vikas gari\\appdata\\roaming\\python\\python313\\site-packages (from tqdm) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "\n",
        "%pip install mido pretty_midi tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import json\n",
        "import mido\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from collections import defaultdict, Counter\n",
        "import re\n",
        "\n",
        "# Optional: tqdm for progress bars (fallback if not installed)\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "except ImportError:\n",
        "    # Simple fallback progress indicator\n",
        "    def tqdm(iterable, desc=None, **kwargs):\n",
        "        if desc:\n",
        "            print(f\"{desc}...\")\n",
        "        return iterable\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Metadata Analysis\n",
        "\n",
        "First, we analyze metadata fields to understand which fields have sufficient coverage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading metadata from: aria-midi-v1-deduped-ext\\metadata.json\n",
            "‚úÖ Loaded 371,053 entries\n",
            "Sample entry keys: ['2', '3', '4', '6', '8']\n",
            "\n",
            "Sample entry (ID: 2):\n",
            "{\n",
            "  \"metadata\": {\n",
            "    \"composer\": \"strauss\",\n",
            "    \"form\": \"waltz\",\n",
            "    \"performer\": \"cziffra\",\n",
            "    \"genre\": \"classical\",\n",
            "    \"music_period\": \"classical\"\n",
            "  },\n",
            "  \"audio_scores\": {\n",
            "    \"0\": 0.9902\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Load metadata\n",
        "metadata_path = Path(\"aria-midi-v1-deduped-ext/metadata.json\")\n",
        "\n",
        "print(f\"Loading metadata from: {metadata_path}\")\n",
        "with open(metadata_path, 'r', encoding='utf-8') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(metadata):,} entries\")\n",
        "print(f\"Sample entry keys: {list(metadata.keys())[:5]}\")\n",
        "\n",
        "# Show sample entry\n",
        "sample_id = list(metadata.keys())[0]\n",
        "print(f\"\\nSample entry (ID: {sample_id}):\")\n",
        "print(json.dumps(metadata[sample_id], indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Field Inclusion Decision\n",
        "\n",
        "Based on coverage threshold (‚â•30%):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "FIELD INCLUSION DECISION (Threshold: ‚â•30% coverage)\n",
            "============================================================\n",
            "\n",
            "‚úÖ INCLUDED FIELDS (3 fields):\n",
            "Field                Coverage     Count           Decision\n",
            "------------------------------------------------------------\n",
            "genre                 74.64%          276,948     REQUIRED\n",
            "composer              39.13%          145,186     OPTIONAL\n",
            "music_period          38.99%          144,691     OPTIONAL\n",
            "\n",
            "‚ùå EXCLUDED FIELDS (6 fields - too sparse):\n",
            "Field                Coverage     Count          \n",
            "------------------------------------------------------------\n",
            "form                  16.40%           60,848\n",
            "difficulty            11.21%           41,587\n",
            "performer              6.85%           25,401\n",
            "opus                   6.58%           24,399\n",
            "key_signature          6.04%           22,403\n",
            "piece_number           4.70%           17,457\n",
            "\n",
            "üìä Summary:\n",
            "  Total fields analyzed: 9\n",
            "  Included: 3 (33.3%)\n",
            "  Excluded: 6 (66.7%)\n"
          ]
        }
      ],
      "source": [
        "# Determine which fields to include/exclude based on coverage\n",
        "COVERAGE_THRESHOLD = 30.0\n",
        "\n",
        "included_fields = []\n",
        "excluded_fields = []\n",
        "\n",
        "for field in sorted(analysis['fields']):\n",
        "    count = analysis['presence'][field]\n",
        "    coverage = (count / analysis['total']) * 100\n",
        "    \n",
        "    if coverage >= COVERAGE_THRESHOLD:\n",
        "        included_fields.append((field, coverage, count))\n",
        "    else:\n",
        "        excluded_fields.append((field, coverage, count))\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FIELD INCLUSION DECISION (Threshold: ‚â•30% coverage)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n‚úÖ INCLUDED FIELDS ({len(included_fields)} fields):\")\n",
        "print(f\"{'Field':<20} {'Coverage':<12} {'Count':<15} {'Decision'}\")\n",
        "print(\"-\" * 60)\n",
        "for field, coverage, count in sorted(included_fields, key=lambda x: x[1], reverse=True):\n",
        "    decision = \"REQUIRED\" if coverage >= 70 else \"RECOMMENDED\" if coverage >= 50 else \"OPTIONAL\"\n",
        "    print(f\"{field:<20} {coverage:>6.2f}%     {count:>12,}     {decision}\")\n",
        "\n",
        "print(f\"\\n‚ùå EXCLUDED FIELDS ({len(excluded_fields)} fields - too sparse):\")\n",
        "print(f\"{'Field':<20} {'Coverage':<12} {'Count':<15}\")\n",
        "print(\"-\" * 60)\n",
        "for field, coverage, count in sorted(excluded_fields, key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{field:<20} {coverage:>6.2f}%     {count:>12,}\")\n",
        "\n",
        "print(f\"\\nüìä Summary:\")\n",
        "print(f\"  Total fields analyzed: {len(analysis['fields'])}\")\n",
        "print(f\"  Included: {len(included_fields)} ({len(included_fields)/len(analysis['fields'])*100:.1f}%)\")\n",
        "print(f\"  Excluded: {len(excluded_fields)} ({len(excluded_fields)/len(analysis['fields'])*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing metadata fields...\n",
            "\n",
            "üìä Metadata Analysis Results:\n",
            "Total entries: 371,053\n",
            "Empty metadata: 52,060 (14.03%)\n",
            "Unique fields: 9\n",
            "\n",
            "Field                Count        Coverage    \n",
            "--------------------------------------------\n",
            "composer             145,186       39.13%\n",
            "difficulty           41,587        11.21%\n",
            "form                 60,848        16.40%\n",
            "genre                276,948       74.64%\n",
            "key_signature        22,403         6.04%\n",
            "music_period         144,691       38.99%\n",
            "opus                 24,399         6.58%\n",
            "performer            25,401         6.85%\n",
            "piece_number         17,457         4.70%\n"
          ]
        }
      ],
      "source": [
        "# Analyze metadata field coverage\n",
        "def analyze_metadata_fields(metadata_dict, sample_size=None):\n",
        "    \"\"\"Analyze which metadata fields exist and their coverage\"\"\"\n",
        "    all_fields = set()\n",
        "    field_presence = defaultdict(int)\n",
        "    field_values = defaultdict(Counter)\n",
        "    total_entries = 0\n",
        "    empty_count = 0\n",
        "    \n",
        "    entries = list(metadata_dict.items())\n",
        "    if sample_size:\n",
        "        entries = entries[:sample_size]\n",
        "    \n",
        "    for entry_id, entry_data in entries:\n",
        "        total_entries += 1\n",
        "        metadata_fields = entry_data.get('metadata', {})\n",
        "        \n",
        "        if not metadata_fields:\n",
        "            empty_count += 1\n",
        "            continue\n",
        "        \n",
        "        for field, value in metadata_fields.items():\n",
        "            all_fields.add(field)\n",
        "            field_presence[field] += 1\n",
        "            \n",
        "            if isinstance(value, (int, float)):\n",
        "                field_values[field][str(value)] += 1\n",
        "            elif isinstance(value, str):\n",
        "                field_values[field][value.lower()] += 1\n",
        "    \n",
        "    return {\n",
        "        'total': total_entries,\n",
        "        'empty': empty_count,\n",
        "        'fields': all_fields,\n",
        "        'presence': dict(field_presence),\n",
        "        'values': dict(field_values)\n",
        "    }\n",
        "\n",
        "# Run analysis\n",
        "print(\"Analyzing metadata fields...\")\n",
        "analysis = analyze_metadata_fields(metadata)\n",
        "\n",
        "print(f\"\\nüìä Metadata Analysis Results:\")\n",
        "print(f\"Total entries: {analysis['total']:,}\")\n",
        "print(f\"Empty metadata: {analysis['empty']:,} ({analysis['empty']/analysis['total']*100:.2f}%)\")\n",
        "print(f\"Unique fields: {len(analysis['fields'])}\")\n",
        "\n",
        "# Print coverage for each field\n",
        "print(f\"\\n{'Field':<20} {'Count':<12} {'Coverage':<12}\")\n",
        "print(\"-\" * 44)\n",
        "for field in sorted(analysis['fields']):\n",
        "    count = analysis['presence'][field]\n",
        "    coverage = (count / analysis['total']) * 100\n",
        "    print(f\"{field:<20} {count:<12,} {coverage:>6.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Metadata Tokenizer\n",
        "\n",
        "Create a tokenizer that converts metadata dictionaries to tokens, handling missing fields gracefully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing MetadataTokenizer:\n",
            "  Test 1: {'genre': 'classical', 'music_period': 'romantic', 'composer': 'Chopin'}\n",
            "    ‚Üí Tokens: ['START', 'GENRE:classical', 'PERIOD:romantic', 'COMPOSER:chopin']\n",
            "\n",
            "  Test 2: {'genre': 'jazz', 'music_period': 'modern'}\n",
            "    ‚Üí Tokens: ['START', 'GENRE:jazz', 'PERIOD:modern']\n",
            "\n",
            "  Test 3: {'genre': 'pop'}\n",
            "    ‚Üí Tokens: ['START', 'GENRE:pop']\n",
            "\n",
            "  Test 4: {}\n",
            "    ‚Üí Tokens: ['START']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Metadata Tokenizer Class\n",
        "# Based on coverage analysis - only fields with ‚â•30% coverage are included\n",
        "\n",
        "FIELD_COVERAGE_THRESHOLD = 30.0  # Minimum coverage % to include a field\n",
        "\n",
        "# Field Decision Matrix (based on analysis):\n",
        "# ‚úÖ INCLUDE (>30% coverage):\n",
        "#   - genre: 74.64% - REQUIRED (highest coverage)\n",
        "#   - music_period: 38.99% - RECOMMENDED\n",
        "#   - composer: 39.13% - OPTIONAL (requires normalization, high cardinality)\n",
        "#\n",
        "# ‚ùå EXCLUDE (<30% coverage - too sparse):\n",
        "#   - form: 16.40%\n",
        "#   - difficulty: 11.21%\n",
        "#   - key_signature: 6.04%\n",
        "#   - opus: 6.58%\n",
        "#   - performer: 6.85%\n",
        "#   - piece_number: 4.70%\n",
        "\n",
        "class MetadataTokenizer:\n",
        "    \"\"\"\n",
        "    Converts metadata to tokens based on field coverage analysis.\n",
        "    \n",
        "    Only includes fields with ‚â•30% coverage to ensure sufficient training signal.\n",
        "    Fields below threshold are automatically excluded.\n",
        "    \n",
        "    Included fields:\n",
        "    - genre (74.64%) - Always included if present\n",
        "    - music_period (38.99%) - Included if present\n",
        "    - composer (39.13%) - Optional, only top-N composers (requires normalization)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, include_composer=True, top_n_composers=100):\n",
        "        self.include_composer = include_composer\n",
        "        \n",
        "        # Valid genres (74.64% coverage)\n",
        "        self.valid_genres = {\n",
        "            'classical', 'pop', 'soundtrack', 'jazz', 'rock', \n",
        "            'folk', 'ambient', 'ragtime', 'blues', 'atonal'\n",
        "        }\n",
        "        \n",
        "        # Valid music periods (38.99% coverage)\n",
        "        self.valid_periods = {\n",
        "            'contemporary', 'modern', 'romantic', 'classical', \n",
        "            'baroque', 'impressionist'\n",
        "        }\n",
        "        \n",
        "        # Top composers (load from actual analysis)\n",
        "        self.top_composers = self._load_top_composers(top_n_composers)\n",
        "    \n",
        "    def _load_top_composers(self, n):\n",
        "        \"\"\"Load top N composers\"\"\"\n",
        "        # Based on dataset analysis - you can extend this\n",
        "        top = {\n",
        "            'hisaishi', 'satie', 'yiruma', 'einaudi', 'joplin',\n",
        "            'chopin', 'beethoven', 'bach', 'mozart', 'debussy',\n",
        "            'schubert', 'schumann', 'liszt', 'rachmaninoff', 'tchaikovsky',\n",
        "            'ravel', 'poulenc', 'faure', 'bartok'\n",
        "        }\n",
        "        return {self._normalize_composer(c) for c in top}\n",
        "    \n",
        "    def _normalize_composer(self, composer):\n",
        "        \"\"\"Normalize composer name\"\"\"\n",
        "        if not composer:\n",
        "            return \"\"\n",
        "        normalized = composer.lower().strip()\n",
        "        # Remove accents\n",
        "        normalized = normalized.replace('√©', 'e').replace('√®', 'e')\n",
        "        normalized = normalized.replace('√°', 'a').replace('√†', 'a')\n",
        "        normalized = normalized.replace('√≠', 'i').replace('√¨', 'i')\n",
        "        normalized = normalized.replace('√≥', 'o').replace('√≤', 'o')\n",
        "        normalized = normalized.replace('√∫', 'u').replace('√π', 'u')\n",
        "        normalized = normalized.replace('√±', 'n')\n",
        "        # Remove special chars\n",
        "        normalized = re.sub(r'[^a-z0-9\\s-]', '', normalized)\n",
        "        normalized = re.sub(r'\\s+', ' ', normalized).strip()\n",
        "        return normalized\n",
        "    \n",
        "    def metadata_to_tokens(self, metadata, include_start=True):\n",
        "        \"\"\"Convert metadata dict to token list\"\"\"\n",
        "        tokens = []\n",
        "        if include_start:\n",
        "            tokens.append(\"START\")\n",
        "        \n",
        "        # Genre (74.64% coverage)\n",
        "        if metadata.get('genre'):\n",
        "            genre = metadata['genre'].lower().strip()\n",
        "            if genre in self.valid_genres:\n",
        "                tokens.append(f\"GENRE:{genre}\")\n",
        "        \n",
        "        # Music period (38.99% coverage)\n",
        "        if metadata.get('music_period'):\n",
        "            period = metadata['music_period'].lower().strip()\n",
        "            if period in self.valid_periods:\n",
        "                tokens.append(f\"PERIOD:{period}\")\n",
        "        \n",
        "        # Composer (39.13% coverage) - optional\n",
        "        if self.include_composer and metadata.get('composer'):\n",
        "            composer = self._normalize_composer(metadata['composer'])\n",
        "            if composer in self.top_composers:\n",
        "                tokens.append(f\"COMPOSER:{composer}\")\n",
        "        \n",
        "        return tokens\n",
        "\n",
        "# Test the tokenizer\n",
        "tokenizer = MetadataTokenizer(include_composer=True)\n",
        "\n",
        "test_metadata = [\n",
        "    {\"genre\": \"classical\", \"music_period\": \"romantic\", \"composer\": \"Chopin\"},\n",
        "    {\"genre\": \"jazz\", \"music_period\": \"modern\"},  # No composer\n",
        "    {\"genre\": \"pop\"},  # Minimal\n",
        "    {}  # Empty\n",
        "]\n",
        "\n",
        "print(\"Testing MetadataTokenizer:\")\n",
        "for i, meta in enumerate(test_metadata, 1):\n",
        "    tokens = tokenizer.metadata_to_tokens(meta)\n",
        "    print(f\"  Test {i}: {meta}\")\n",
        "    print(f\"    ‚Üí Tokens: {tokens}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: MIDI to Tokens Conversion\n",
        "\n",
        "Convert MIDI files to token sequences using event-based representation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with: 000002_0.mid\n",
            "  Generated 37741 tokens\n",
            "  First 20 tokens: ['TIME_SHIFT:1280', 'NOTE_ON:56', 'VELOCITY:60', 'TIME_SHIFT:30', 'NOTE_ON:58', 'VELOCITY:70', 'TIME_SHIFT:20', 'NOTE_OFF:56', 'TIME_SHIFT:10', 'NOTE_ON:32', 'VELOCITY:85', 'NOTE_ON:44', 'VELOCITY:100', 'TIME_SHIFT:10', 'NOTE_ON:39', 'VELOCITY:65', 'TIME_SHIFT:10', 'NOTE_ON:56', 'VELOCITY:90', 'TIME_SHIFT:800']\n"
          ]
        }
      ],
      "source": [
        "# MIDI to Tokens Converter\n",
        "class MIDITokenizer:\n",
        "    \"\"\"\n",
        "    Converts MIDI files to token sequences.\n",
        "    Uses event-based representation: TIME_SHIFT, NOTE_ON, NOTE_OFF, VELOCITY\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, time_quantization=10):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            time_quantization: Quantize time to this many ticks (smaller = finer resolution)\n",
        "        \"\"\"\n",
        "        self.time_quantization = time_quantization\n",
        "    \n",
        "    def midi_to_tokens(self, midi_path: Path) -> List[str]:\n",
        "        \"\"\"\n",
        "        Convert MIDI file to token sequence\n",
        "        \n",
        "        Returns list of tokens like: [\"TIME_SHIFT:0\", \"NOTE_ON:60\", \"VELOCITY:80\", ...]\n",
        "        \"\"\"\n",
        "        try:\n",
        "            mid = mido.MidiFile(midi_path)\n",
        "            tokens = []\n",
        "            current_time = 0\n",
        "            \n",
        "            # Process all tracks\n",
        "            for track in mid.tracks:\n",
        "                for msg in track:\n",
        "                    # Accumulate time\n",
        "                    current_time += int(msg.time)\n",
        "                    \n",
        "                    # Quantize time\n",
        "                    quantized_time = (current_time // self.time_quantization) * self.time_quantization\n",
        "                    \n",
        "                    # Note On (velocity > 0)\n",
        "                    if msg.type == 'note_on' and msg.velocity > 0:\n",
        "                        if quantized_time > 0:\n",
        "                            tokens.append(f\"TIME_SHIFT:{quantized_time}\")\n",
        "                        tokens.append(f\"NOTE_ON:{msg.note}\")\n",
        "                        tokens.append(f\"VELOCITY:{msg.velocity}\")\n",
        "                        current_time = 0\n",
        "                    \n",
        "                    # Note Off (or Note On with velocity 0)\n",
        "                    elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
        "                        if quantized_time > 0:\n",
        "                            tokens.append(f\"TIME_SHIFT:{quantized_time}\")\n",
        "                        tokens.append(f\"NOTE_OFF:{msg.note}\")\n",
        "                        current_time = 0\n",
        "            \n",
        "            return tokens\n",
        "        \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_path}: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def tokens_to_vocab_mapping(self, tokens_list: List[List[str]]) -> Dict[str, int]:\n",
        "        \"\"\"Create vocabulary mapping from all tokens\"\"\"\n",
        "        all_tokens = set()\n",
        "        for tokens in tokens_list:\n",
        "            all_tokens.update(tokens)\n",
        "        \n",
        "        # Special tokens\n",
        "        vocab = {\n",
        "            \"<PAD>\": 0,\n",
        "            \"<UNK>\": 1,\n",
        "            \"<START>\": 2,\n",
        "            \"<END>\": 3,\n",
        "        }\n",
        "        \n",
        "        # Add all unique tokens\n",
        "        for token in sorted(all_tokens):\n",
        "            if token not in vocab:\n",
        "                vocab[token] = len(vocab)\n",
        "        \n",
        "        return vocab\n",
        "\n",
        "# Test MIDI tokenizer\n",
        "midi_tokenizer = MIDITokenizer(time_quantization=10)\n",
        "\n",
        "# Test with a sample MIDI file (if available)\n",
        "data_path = Path(\"aria-midi-v1-deduped-ext/data\")\n",
        "if data_path.exists():\n",
        "    # Find first MIDI file\n",
        "    midi_files = list(data_path.glob(\"**/*.mid\"))\n",
        "    if midi_files:\n",
        "        test_midi = midi_files[0]\n",
        "        print(f\"Testing with: {test_midi.name}\")\n",
        "        tokens = midi_tokenizer.midi_to_tokens(test_midi)\n",
        "        print(f\"  Generated {len(tokens)} tokens\")\n",
        "        print(f\"  First 20 tokens: {tokens[:20]}\")\n",
        "    else:\n",
        "        print(\"No MIDI files found for testing\")\n",
        "else:\n",
        "    print(\"Data directory not found - will process during full preprocessing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Balanced Dataset Sampling\n",
        "\n",
        "**Problem:** Using full dataset creates bias:\n",
        "1. **Composer bias**: Only top-N composers get tokens, rest get no composer ‚Üí most files have no composer token\n",
        "2. **Empty metadata bias**: 14% of files have empty metadata ‚Üí too many unconditional examples\n",
        "3. **Genre bias**: Some genres may dominate\n",
        "\n",
        "**Solution:** Create a balanced subset that ensures:\n",
        "- Representative composer distribution\n",
        "- Limited empty metadata samples\n",
        "- Balanced genre distribution\n",
        "- Similar number of examples per category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing metadata distribution for balancing...\n",
            "\n",
            "üìä Distribution Analysis:\n",
            "  Files with composer: 91,518\n",
            "  Files without composer: 103,338\n",
            "  Empty metadata: 28,507\n",
            "\n",
            "  Top 10 composers:\n",
            "    hisaishi: 2,013\n",
            "    satie: 1,410\n",
            "    yiruma: 1,040\n",
            "    bach: 1,018\n",
            "    joplin: 922\n",
            "    handel: 910\n",
            "    einaudi: 902\n",
            "    uematsu: 788\n",
            "    gershwin: 691\n",
            "    sakamoto: 682\n",
            "\n",
            "  Genre distribution:\n",
            "    classical: 70,933\n",
            "    pop: 44,616\n",
            "    soundtrack: 32,726\n",
            "    jazz: 10,937\n",
            "    rock: 3,636\n",
            "    folk: 3,120\n",
            "    ragtime: 2,233\n",
            "    ambient: 1,974\n",
            "    blues: 627\n",
            "    atonal: 69\n"
          ]
        }
      ],
      "source": [
        "# Balanced sampling configuration\n",
        "SAMPLING_CONFIG = {\n",
        "    'target_samples_per_category': 1000,  # Target samples per composer/genre combination\n",
        "    'max_empty_metadata_ratio': 0.05,  # Max 5% of dataset with empty metadata\n",
        "    'max_per_composer': 500,  # Max samples per composer (top-N)\n",
        "    'max_per_genre': None,  # None = no limit, or set number to balance\n",
        "    'composer_strategy': 'balanced',  # 'balanced' or 'exclude'\n",
        "    # If 'exclude': Don't use composer field at all (avoids bias completely)\n",
        "    # If 'balanced': Include top-N composers with balanced samples\n",
        "}\n",
        "\n",
        "def analyze_metadata_distribution(metadata_dict):\n",
        "    \"\"\"Analyze distribution of metadata fields for balancing\"\"\"\n",
        "    stats = {\n",
        "        'by_composer': defaultdict(int),\n",
        "        'by_genre': defaultdict(int),\n",
        "        'by_period': defaultdict(int),\n",
        "        'by_composer_genre': defaultdict(int),\n",
        "        'empty_metadata': [],\n",
        "        'with_composer': [],\n",
        "        'no_composer': [],\n",
        "    }\n",
        "    \n",
        "    for entry_id, entry_data in metadata_dict.items():\n",
        "        metadata = entry_data.get('metadata', {})\n",
        "        audio_scores = entry_data.get('audio_scores', {})\n",
        "        \n",
        "        # Check quality\n",
        "        if not audio_scores:\n",
        "            continue\n",
        "        best_score = max(audio_scores.values())\n",
        "        if best_score < 0.97:  # Quality threshold\n",
        "            continue\n",
        "        \n",
        "        genre = metadata.get('genre', '').lower() if metadata.get('genre') else None\n",
        "        composer = metadata.get('composer', '').lower() if metadata.get('composer') else None\n",
        "        period = metadata.get('music_period', '').lower() if metadata.get('music_period') else None\n",
        "        \n",
        "        if not metadata:\n",
        "            stats['empty_metadata'].append(entry_id)\n",
        "        else:\n",
        "            if genre:\n",
        "                stats['by_genre'][genre] += 1\n",
        "            if composer:\n",
        "                stats['by_composer'][composer] += 1\n",
        "                stats['with_composer'].append(entry_id)\n",
        "            else:\n",
        "                stats['no_composer'].append(entry_id)\n",
        "            if period:\n",
        "                stats['by_period'][period] += 1\n",
        "            if composer and genre:\n",
        "                stats['by_composer_genre'][(composer, genre)] += 1\n",
        "    \n",
        "    return stats\n",
        "\n",
        "# Analyze distribution\n",
        "print(\"Analyzing metadata distribution for balancing...\")\n",
        "distribution = analyze_metadata_distribution(metadata)\n",
        "\n",
        "print(f\"\\nüìä Distribution Analysis:\")\n",
        "print(f\"  Files with composer: {len(distribution['with_composer']):,}\")\n",
        "print(f\"  Files without composer: {len(distribution['no_composer']):,}\")\n",
        "print(f\"  Empty metadata: {len(distribution['empty_metadata']):,}\")\n",
        "\n",
        "print(f\"\\n  Top 10 composers:\")\n",
        "for composer, count in sorted(distribution['by_composer'].items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(f\"    {composer}: {count:,}\")\n",
        "\n",
        "print(f\"\\n  Genre distribution:\")\n",
        "for genre, count in sorted(distribution['by_genre'].items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"    {genre}: {count:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating balanced dataset sample...\n",
            "============================================================\n",
            "‚úÖ Using BALANCED composer sampling\n",
            "  Composer 'chopin': 64/388 samples\n",
            "  Composer 'rachmaninoff': 64/175 samples\n",
            "  Composer 'satie': 64/1410 samples\n",
            "  Composer 'bach': 64/1018 samples\n",
            "  Composer 'beethoven': 64/314 samples\n",
            "  Composer 'yiruma': 64/1040 samples\n",
            "  Composer 'hisaishi': 64/2013 samples\n",
            "  Composer 'poulenc': 64/577 samples\n",
            "  Composer 'debussy': 64/170 samples\n",
            "  Composer 'joplin': 64/922 samples\n",
            "  Composer 'mozart': 64/398 samples\n",
            "  Composer 'schubert': 64/495 samples\n",
            "  Composer 'bartok': 64/167 samples\n",
            "  Composer 'einaudi': 64/902 samples\n",
            "  Composer 'schumann': 64/363 samples\n",
            "  Composer 'liszt': 64/567 samples\n",
            "  Composer 'ravel': 64/64 samples\n",
            "  Composer 'faure': 64/208 samples\n",
            "  Composer 'tchaikovsky': 64/168 samples\n",
            "  No composer: 1216 samples\n",
            "  Other composers (excluded to avoid bias): 80,159\n",
            "\n",
            "‚úÖ Balanced sample created:\n",
            "  Total samples: 3,843\n",
            "  Empty metadata: 1,425 (37.1%)\n",
            "\n",
            "üìä Final balanced dataset:\n",
            "  Original size: 371,053\n",
            "  Balanced size: 3,843\n",
            "  Reduction: 99.0%\n",
            "\n",
            "üìà Final dataset distribution:\n",
            "  Empty metadata: 1,689 (44.0%)\n",
            "  Target was: <5%\n",
            "\n",
            "  Composer distribution in balanced set:\n",
            "    einaudi: 64\n",
            "    ravel: 64\n",
            "    schubert: 64\n",
            "    joplin: 64\n",
            "    bartok: 64\n",
            "    beethoven: 64\n",
            "    mozart: 64\n",
            "    satie: 64\n",
            "    tchaikovsky: 64\n",
            "    faure: 64\n",
            "    schumann: 64\n",
            "    debussy: 64\n",
            "    bach: 64\n",
            "    liszt: 64\n",
            "    hisaishi: 64\n",
            "    yiruma: 64\n",
            "    chopin: 64\n",
            "    rachmaninoff: 64\n",
            "    poulenc: 64\n",
            "    No composer: 2,627\n"
          ]
        }
      ],
      "source": [
        "# Balanced sampling function\n",
        "import random\n",
        "\n",
        "def create_balanced_sample(metadata_dict, sampling_config, tokenizer):\n",
        "    \"\"\"\n",
        "    Create a balanced, unbiased subset of the dataset\n",
        "    \n",
        "    Strategy:\n",
        "    1. If composer_strategy == 'exclude': Don't use composer at all (eliminates bias)\n",
        "    2. If composer_strategy == 'balanced': Sample equally from top-N composers + no-composer\n",
        "    3. Limit empty metadata to max ratio\n",
        "    4. Balance genres proportionally\n",
        "    \"\"\"\n",
        "    random.seed(42)  # For reproducibility\n",
        "    \n",
        "    # Analyze distribution\n",
        "    distribution = analyze_metadata_distribution(metadata_dict)\n",
        "    \n",
        "    # Strategy decision\n",
        "    if sampling_config['composer_strategy'] == 'exclude':\n",
        "        print(\"‚ö†Ô∏è  Composer field will be EXCLUDED to avoid bias\")\n",
        "        print(\"   All composer tokens will be skipped during tokenization\")\n",
        "        # Don't filter by composer - just balance other fields\n",
        "        composer_sampling = None\n",
        "    else:\n",
        "        print(\"‚úÖ Using BALANCED composer sampling\")\n",
        "        \n",
        "        # Get top composers (based on tokenizer's top_composers)\n",
        "        top_composers = set(tokenizer.top_composers)\n",
        "        \n",
        "        # Group by composer category\n",
        "        composer_groups = {\n",
        "            'top_composer': defaultdict(list),  # Files with top-N composers\n",
        "            'other_composer': [],  # Files with other composers\n",
        "            'no_composer': []  # Files without composer\n",
        "        }\n",
        "        \n",
        "        for entry_id, entry_data in metadata_dict.items():\n",
        "            metadata = entry_data.get('metadata', {})\n",
        "            audio_scores = entry_data.get('audio_scores', {})\n",
        "            \n",
        "            if not audio_scores:\n",
        "                continue\n",
        "            if max(audio_scores.values()) < 0.97:\n",
        "                continue\n",
        "            \n",
        "            composer = metadata.get('composer', '').lower() if metadata.get('composer') else None\n",
        "            normalized_composer = tokenizer._normalize_composer(composer) if composer else None\n",
        "            \n",
        "            if normalized_composer and normalized_composer in top_composers:\n",
        "                composer_groups['top_composer'][normalized_composer].append(entry_id)\n",
        "            elif composer:\n",
        "                composer_groups['other_composer'].append(entry_id)\n",
        "            else:\n",
        "                composer_groups['no_composer'].append(entry_id)\n",
        "        \n",
        "        # Sample strategy: equal number from each top composer + no-composer group\n",
        "        max_per_category = sampling_config['max_per_composer']\n",
        "        samples_per_composer = min(\n",
        "            max_per_category,\n",
        "            min(len(files) for files in composer_groups['top_composer'].values()) if composer_groups['top_composer'] else 0\n",
        "        )\n",
        "        \n",
        "        # Ensure no-composer group has similar size\n",
        "        no_composer_limit = samples_per_composer * len(composer_groups['top_composer'])\n",
        "        \n",
        "        sampled_ids = set()\n",
        "        \n",
        "        # Sample from each top composer\n",
        "        for composer, file_ids in composer_groups['top_composer'].items():\n",
        "            sampled = random.sample(file_ids, min(samples_per_composer, len(file_ids)))\n",
        "            sampled_ids.update(sampled)\n",
        "            print(f\"  Composer '{composer}': {len(sampled)}/{len(file_ids)} samples\")\n",
        "        \n",
        "        # Sample from no-composer group\n",
        "        no_composer_sample = random.sample(\n",
        "            composer_groups['no_composer'], \n",
        "            min(no_composer_limit, len(composer_groups['no_composer']))\n",
        "        )\n",
        "        sampled_ids.update(no_composer_sample)\n",
        "        print(f\"  No composer: {len(no_composer_sample)} samples\")\n",
        "        \n",
        "        # Skip other_composer (would create bias)\n",
        "        print(f\"  Other composers (excluded to avoid bias): {len(composer_groups['other_composer']):,}\")\n",
        "        \n",
        "        composer_sampling = sampled_ids\n",
        "    \n",
        "    # Handle empty metadata limitation\n",
        "    max_empty = int(sampling_config['max_empty_metadata_ratio'] * len(distribution['empty_metadata']))\n",
        "    empty_sample = random.sample(distribution['empty_metadata'], min(max_empty, len(distribution['empty_metadata'])))\n",
        "    \n",
        "    if composer_sampling:\n",
        "        final_ids = list(composer_sampling) + empty_sample\n",
        "    else:\n",
        "        # If excluding composer, sample from all (with empty metadata limit)\n",
        "        all_ids = distribution['with_composer'] + distribution['no_composer']\n",
        "        final_ids = random.sample(all_ids, min(50000, len(all_ids))) + empty_sample\n",
        "    \n",
        "    # Remove duplicates\n",
        "    final_ids = list(set(final_ids))\n",
        "    \n",
        "    print(f\"\\n‚úÖ Balanced sample created:\")\n",
        "    print(f\"  Total samples: {len(final_ids):,}\")\n",
        "    print(f\"  Empty metadata: {len(empty_sample):,} ({len(empty_sample)/len(final_ids)*100:.1f}%)\")\n",
        "    \n",
        "    return final_ids\n",
        "\n",
        "# Create balanced sample\n",
        "print(\"Creating balanced dataset sample...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Option 1: Balanced composer sampling (recommended)\n",
        "# - Equal samples from top-N composers\n",
        "# - Equal samples from no-composer group\n",
        "# - Excludes \"other\" composers to avoid bias\n",
        "\n",
        "# Option 2: Exclude composer entirely (alternative - eliminates composer bias completely)\n",
        "# SAMPLING_CONFIG['composer_strategy'] = 'exclude'\n",
        "\n",
        "balanced_ids = create_balanced_sample(metadata, SAMPLING_CONFIG, tokenizer)\n",
        "\n",
        "# Create filtered metadata dict\n",
        "balanced_metadata = {entry_id: metadata[entry_id] for entry_id in balanced_ids if entry_id in metadata}\n",
        "\n",
        "print(f\"\\nüìä Final balanced dataset:\")\n",
        "print(f\"  Original size: {len(metadata):,}\")\n",
        "print(f\"  Balanced size: {len(balanced_metadata):,}\")\n",
        "print(f\"  Reduction: {(1 - len(balanced_metadata)/len(metadata))*100:.1f}%\")\n",
        "\n",
        "# Analyze final distribution\n",
        "print(\"\\nüìà Final dataset distribution:\")\n",
        "empty_count = sum(1 for entry in balanced_metadata.values() if not entry.get('metadata', {}))\n",
        "print(f\"  Empty metadata: {empty_count:,} ({empty_count/len(balanced_metadata)*100:.1f}%)\")\n",
        "print(f\"  Target was: <{SAMPLING_CONFIG['max_empty_metadata_ratio']*100:.0f}%\")\n",
        "\n",
        "# Show composer distribution\n",
        "composer_counts = defaultdict(int)\n",
        "for entry in balanced_metadata.values():\n",
        "    composer = entry.get('metadata', {}).get('composer', '').lower() if entry.get('metadata', {}).get('composer') else None\n",
        "    if composer:\n",
        "        normalized = tokenizer._normalize_composer(composer)\n",
        "        if normalized in tokenizer.top_composers:\n",
        "            composer_counts[normalized] += 1\n",
        "\n",
        "print(f\"\\n  Composer distribution in balanced set:\")\n",
        "for composer, count in sorted(composer_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"    {composer}: {count:,}\")\n",
        "\n",
        "no_composer_count = sum(1 for entry in balanced_metadata.values() \n",
        "                       if not entry.get('metadata', {}).get('composer'))\n",
        "print(f\"    No composer: {no_composer_count:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Find MIDI Files from Metadata\n",
        "\n",
        "Given a metadata entry ID and audio index, find the corresponding MIDI file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing file finding:\n",
            "  ‚úÖ ID 2: 000002_0.mid\n",
            "  ‚úÖ ID 3: 000003_0.mid\n",
            "  ‚úÖ ID 4: 000004_0.mid\n",
            "  ‚úÖ ID 6: 000006_0.mid\n",
            "  ‚úÖ ID 8: 000008_0.mid\n"
          ]
        }
      ],
      "source": [
        "# Function to find MIDI file path\n",
        "def find_midi_file(file_id: str, audio_index: str, data_root: Path) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Find MIDI file given its ID and audio index\n",
        "    \n",
        "    Args:\n",
        "        file_id: Numeric ID as string (e.g., \"2\", \"647\")\n",
        "        audio_index: Audio score index (e.g., \"0\", \"1\")\n",
        "        data_root: Root directory containing data/ folder\n",
        "    \n",
        "    Returns:\n",
        "        Path to MIDI file if found, None otherwise\n",
        "    \"\"\"\n",
        "    # Format filename: 000002_0.mid\n",
        "    padded_id = file_id.zfill(6)\n",
        "    filename = f\"{padded_id}_{audio_index}.mid\"\n",
        "    \n",
        "    # Search in all subdirectories (aa, ab, ac, etc.)\n",
        "    for subfolder in data_root.iterdir():\n",
        "        if subfolder.is_dir() and len(subfolder.name) == 2:\n",
        "            filepath = subfolder / filename\n",
        "            if filepath.exists():\n",
        "                return filepath\n",
        "    \n",
        "    return None\n",
        "\n",
        "# Test file finding\n",
        "data_root = Path(\"aria-midi-v1-deduped-ext/data\")\n",
        "if data_root.exists():\n",
        "    # Test with first few entries\n",
        "    test_ids = list(metadata.keys())[:5]\n",
        "    print(\"Testing file finding:\")\n",
        "    for entry_id in test_ids:\n",
        "        entry = metadata[entry_id]\n",
        "        audio_scores = entry.get('audio_scores', {})\n",
        "        if audio_scores:\n",
        "            audio_idx = list(audio_scores.keys())[0]\n",
        "            filepath = find_midi_file(entry_id, audio_idx, data_root)\n",
        "            if filepath:\n",
        "                print(f\"  ‚úÖ ID {entry_id}: {filepath.name}\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå ID {entry_id}: Not found\")\n",
        "else:\n",
        "    print(\"Data directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Full Preprocessing Pipeline\n",
        "\n",
        "Process all entries: combine metadata tokens + MIDI tokens into training sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing Configuration:\n",
            "  min_quality_score: 0.97\n",
            "  max_sequence_length: 2048\n",
            "  time_quantization: 10\n",
            "  data_root: aria-midi-v1-deduped-ext\\data\n",
            "  output_dir: processed_data\n",
            "  sample_size: None\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing configuration\n",
        "CONFIG = {\n",
        "    'min_quality_score': 0.97,  # Only use high-quality transcriptions\n",
        "    'max_sequence_length': 2048,  # Maximum tokens per sequence\n",
        "    'time_quantization': 10,  # MIDI time quantization\n",
        "    'data_root': Path(\"aria-midi-v1-deduped-ext/data\"),\n",
        "    'output_dir': Path(\"processed_data\"),\n",
        "    'sample_size': None,  # Set to number for testing, None for full dataset\n",
        "}\n",
        "\n",
        "# Create output directory\n",
        "CONFIG['output_dir'].mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Preprocessing Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing preprocessing pipeline on sample entries...\n",
            "  ‚úÖ ID 2: 2048 tokens\n",
            "     Metadata tokens: 3\n",
            "     MIDI tokens: 2044\n",
            "  ‚úÖ ID 3: 2048 tokens\n",
            "     Metadata tokens: 3\n",
            "     MIDI tokens: 2044\n",
            "  ‚ùå ID 4: Failed (quality too low or file not found)\n",
            "  ‚úÖ ID 6: 2048 tokens\n",
            "     Metadata tokens: 1\n",
            "     MIDI tokens: 2046\n",
            "  ‚úÖ ID 8: 2048 tokens\n",
            "     Metadata tokens: 3\n",
            "     MIDI tokens: 2044\n",
            "  ‚úÖ ID 9: 2048 tokens\n",
            "     Metadata tokens: 2\n",
            "     MIDI tokens: 2045\n",
            "  ‚úÖ ID 10: 2048 tokens\n",
            "     Metadata tokens: 3\n",
            "     MIDI tokens: 2044\n",
            "  ‚úÖ ID 11: 2048 tokens\n",
            "     Metadata tokens: 2\n",
            "     MIDI tokens: 2045\n",
            "  ‚úÖ ID 12: 2048 tokens\n",
            "     Metadata tokens: 1\n",
            "     MIDI tokens: 2046\n",
            "  ‚ùå ID 13: Failed (quality too low or file not found)\n",
            "\n",
            "Processed 8/10 test entries successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizers\n",
        "meta_tokenizer = MetadataTokenizer(include_composer=True)\n",
        "midi_tokenizer = MIDITokenizer(time_quantization=CONFIG['time_quantization'])\n",
        "\n",
        "def process_entry(entry_id: str, entry_data: Dict, data_root: Path) -> Optional[List[str]]:\n",
        "    \"\"\"\n",
        "    Process a single entry: combine metadata + MIDI tokens\n",
        "    \n",
        "    Returns:\n",
        "        Full token sequence or None if processing fails\n",
        "    \"\"\"\n",
        "    # 1. Filter by quality\n",
        "    audio_scores = entry_data.get('audio_scores', {})\n",
        "    if not audio_scores:\n",
        "        return None\n",
        "    \n",
        "    # Get best quality audio index\n",
        "    best_idx = max(audio_scores.items(), key=lambda x: x[1])[0]\n",
        "    score = audio_scores[best_idx]\n",
        "    \n",
        "    if score < CONFIG['min_quality_score']:\n",
        "        return None\n",
        "    \n",
        "    # 2. Get metadata tokens\n",
        "    metadata_dict = entry_data.get('metadata', {})\n",
        "    metadata_tokens = meta_tokenizer.metadata_to_tokens(metadata_dict, include_start=True)\n",
        "    \n",
        "    # 3. Find and load MIDI file\n",
        "    midi_path = find_midi_file(entry_id, best_idx, data_root)\n",
        "    if not midi_path or not midi_path.exists():\n",
        "        return None\n",
        "    \n",
        "    # 4. Convert MIDI to tokens\n",
        "    midi_tokens = midi_tokenizer.midi_to_tokens(midi_path)\n",
        "    if not midi_tokens:\n",
        "        return None\n",
        "    \n",
        "    # 5. Combine: metadata + MIDI + END token\n",
        "    full_sequence = metadata_tokens + midi_tokens + [\"<END>\"]\n",
        "    \n",
        "    # 6. Truncate if too long\n",
        "    if len(full_sequence) > CONFIG['max_sequence_length']:\n",
        "        # Keep all metadata, truncate MIDI tokens\n",
        "        metadata_len = len(metadata_tokens)\n",
        "        max_midi_len = CONFIG['max_sequence_length'] - metadata_len - 1  # -1 for END\n",
        "        full_sequence = metadata_tokens + midi_tokens[:max_midi_len] + [\"<END>\"]\n",
        "    \n",
        "    return full_sequence\n",
        "\n",
        "# Test processing on a few entries\n",
        "print(\"Testing preprocessing pipeline on sample entries...\")\n",
        "test_entries = list(metadata.items())[:10]\n",
        "processed_count = 0\n",
        "\n",
        "for entry_id, entry_data in test_entries:\n",
        "    sequence = process_entry(entry_id, entry_data, CONFIG['data_root'])\n",
        "    if sequence:\n",
        "        processed_count += 1\n",
        "        print(f\"  ‚úÖ ID {entry_id}: {len(sequence)} tokens\")\n",
        "        print(f\"     Metadata tokens: {len([t for t in sequence if t.startswith(('START', 'GENRE', 'PERIOD', 'COMPOSER'))])}\")\n",
        "        print(f\"     MIDI tokens: {len([t for t in sequence if not t.startswith(('START', 'GENRE', 'PERIOD', 'COMPOSER')) and t != '<END>'])}\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå ID {entry_id}: Failed (quality too low or file not found)\")\n",
        "\n",
        "print(f\"\\nProcessed {processed_count}/{len(test_entries)} test entries successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Process Full Dataset\n",
        "\n",
        "Now process all entries and build vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting dataset processing on BALANCED sample...\n",
            "Using balanced subset: 3,843 entries\n",
            "(Original dataset: 371,053 entries)\n",
            "\n",
            "Processing 3,843 entries...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3843/3843 [02:38<00:00, 24.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Processing complete!\n",
            "  Successful: 3,843\n",
            "  Failed: 0\n",
            "    - Quality filtered: 0\n",
            "    - File not found: 0\n"
          ]
        }
      ],
      "source": [
        "# Process full dataset\n",
        "def process_dataset(metadata_dict, data_root, sample_size=None):\n",
        "    \"\"\"Process entire dataset and build vocabulary\"\"\"\n",
        "    all_sequences = []\n",
        "    failed_count = 0\n",
        "    quality_filtered = 0\n",
        "    file_not_found = 0\n",
        "    \n",
        "    entries = list(metadata_dict.items())\n",
        "    if sample_size:\n",
        "        entries = entries[:sample_size]\n",
        "    \n",
        "    print(f\"Processing {len(entries):,} entries...\")\n",
        "    \n",
        "    for entry_id, entry_data in tqdm(entries, desc=\"Processing\"):\n",
        "        sequence = process_entry(entry_id, entry_data, data_root)\n",
        "        \n",
        "        if sequence is None:\n",
        "            failed_count += 1\n",
        "            # Track failure reasons (simplified)\n",
        "            audio_scores = entry_data.get('audio_scores', {})\n",
        "            if audio_scores:\n",
        "                best_score = max(audio_scores.values())\n",
        "                if best_score < CONFIG['min_quality_score']:\n",
        "                    quality_filtered += 1\n",
        "                else:\n",
        "                    file_not_found += 1\n",
        "            else:\n",
        "                quality_filtered += 1\n",
        "        else:\n",
        "            all_sequences.append({\n",
        "                'entry_id': entry_id,\n",
        "                'sequence': sequence,\n",
        "                'length': len(sequence)\n",
        "            })\n",
        "    \n",
        "    print(f\"\\n‚úÖ Processing complete!\")\n",
        "    print(f\"  Successful: {len(all_sequences):,}\")\n",
        "    print(f\"  Failed: {failed_count:,}\")\n",
        "    print(f\"    - Quality filtered: {quality_filtered:,}\")\n",
        "    print(f\"    - File not found: {file_not_found:,}\")\n",
        "    \n",
        "    return all_sequences\n",
        "\n",
        "# Run processing on BALANCED dataset (not full dataset!)\n",
        "print(\"Starting dataset processing on BALANCED sample...\")\n",
        "print(f\"Using balanced subset: {len(balanced_metadata):,} entries\")\n",
        "print(f\"(Original dataset: {len(metadata):,} entries)\")\n",
        "print()\n",
        "\n",
        "# Use balanced_metadata instead of full metadata to avoid bias\n",
        "all_sequences = process_dataset(balanced_metadata, CONFIG['data_root'], sample_size=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Build Vocabulary\n",
        "\n",
        "Create vocabulary mapping from all processed tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 746 tokens\n",
            "\n",
            "Special tokens:\n",
            "     0: <PAD>\n",
            "     1: <UNK>\n",
            "     2: <START>\n",
            "     3: <END>\n",
            "     4: COMPOSER:bach\n",
            "     5: COMPOSER:bartok\n",
            "     6: COMPOSER:beethoven\n",
            "     7: COMPOSER:chopin\n",
            "     8: COMPOSER:debussy\n",
            "     9: COMPOSER:einaudi\n",
            "\n",
            "Sample tokens:\n",
            "    10: COMPOSER:faure\n",
            "    11: COMPOSER:hisaishi\n",
            "    12: COMPOSER:joplin\n",
            "    13: COMPOSER:liszt\n",
            "    14: COMPOSER:mozart\n",
            "    15: COMPOSER:poulenc\n",
            "    16: COMPOSER:rachmaninoff\n",
            "    17: COMPOSER:ravel\n",
            "    18: COMPOSER:satie\n",
            "    19: COMPOSER:schubert\n",
            "    20: COMPOSER:schumann\n",
            "    21: COMPOSER:tchaikovsky\n",
            "    22: COMPOSER:yiruma\n",
            "    23: GENRE:ambient\n",
            "    24: GENRE:blues\n"
          ]
        }
      ],
      "source": [
        "# Build vocabulary\n",
        "def build_vocabulary(sequences):\n",
        "    \"\"\"Build vocabulary from all token sequences\"\"\"\n",
        "    all_tokens = set()\n",
        "    \n",
        "    for seq_data in sequences:\n",
        "        all_tokens.update(seq_data['sequence'])\n",
        "    \n",
        "    # Special tokens first\n",
        "    vocab = {\n",
        "        \"<PAD>\": 0,\n",
        "        \"<UNK>\": 1,\n",
        "        \"<START>\": 2,\n",
        "        \"<END>\": 3,\n",
        "    }\n",
        "    \n",
        "    # Add all unique tokens\n",
        "    for token in sorted(all_tokens):\n",
        "        if token not in vocab:\n",
        "            vocab[token] = len(vocab)\n",
        "    \n",
        "    # Reverse mapping (id -> token)\n",
        "    id_to_token = {v: k for k, v in vocab.items()}\n",
        "    \n",
        "    return vocab, id_to_token\n",
        "\n",
        "vocab, id_to_token = build_vocabulary(all_sequences)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vocab):,} tokens\")\n",
        "print(f\"\\nSpecial tokens:\")\n",
        "for token, idx in sorted(vocab.items(), key=lambda x: x[1])[:10]:\n",
        "    print(f\"  {idx:4d}: {token}\")\n",
        "\n",
        "print(f\"\\nSample tokens:\")\n",
        "for token, idx in sorted(vocab.items(), key=lambda x: x[1])[10:25]:\n",
        "    print(f\"  {idx:4d}: {token}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Convert Sequences to Token IDs\n",
        "\n",
        "Convert text tokens to numerical IDs for model training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted 3,843 sequences to token IDs\n",
            "\n",
            "Sample sequence (first 20 tokens):\n",
            "  Token IDs: [220, 28, 362, 169, 734, 334, 204, 739, 209, 740, 221, 200, 738, 446, 176, 736, 222, 181, 737, 312]\n",
            "  Tokens:    ['START', 'GENRE:pop', 'TIME_SHIFT:2240', 'NOTE_ON:55', 'VELOCITY:45', 'TIME_SHIFT:20', 'NOTE_ON:90', 'VELOCITY:65', 'NOTE_ON:95', 'VELOCITY:70', 'TIME_SHIFT:10', 'NOTE_ON:86', 'VELOCITY:60', 'TIME_SHIFT:300', 'NOTE_ON:62', 'VELOCITY:50', 'TIME_SHIFT:100', 'NOTE_ON:67', 'VELOCITY:55', 'TIME_SHIFT:180']\n",
            "\n",
            "Sequence length statistics:\n",
            "  Min: 722\n",
            "  Max: 2048\n",
            "  Mean: 2021.1\n",
            "  Median: 2048\n"
          ]
        }
      ],
      "source": [
        "# Convert sequences to token IDs\n",
        "def tokenize_sequences(sequences, vocab):\n",
        "    \"\"\"Convert token sequences to ID sequences\"\"\"\n",
        "    tokenized = []\n",
        "    \n",
        "    for seq_data in sequences:\n",
        "        token_ids = [vocab.get(token, vocab[\"<UNK>\"]) for token in seq_data['sequence']]\n",
        "        tokenized.append({\n",
        "            'entry_id': seq_data['entry_id'],\n",
        "            'token_ids': token_ids,\n",
        "            'length': len(token_ids)\n",
        "        })\n",
        "    \n",
        "    return tokenized\n",
        "\n",
        "# Convert to token IDs\n",
        "tokenized_sequences = tokenize_sequences(all_sequences, vocab)\n",
        "\n",
        "print(f\"Converted {len(tokenized_sequences):,} sequences to token IDs\")\n",
        "print(f\"\\nSample sequence (first 20 tokens):\")\n",
        "sample = tokenized_sequences[0]\n",
        "token_ids = sample['token_ids'][:20]\n",
        "tokens = [id_to_token[tid] for tid in token_ids]\n",
        "print(f\"  Token IDs: {token_ids}\")\n",
        "print(f\"  Tokens:    {tokens}\")\n",
        "\n",
        "# Statistics\n",
        "lengths = [s['length'] for s in tokenized_sequences]\n",
        "print(f\"\\nSequence length statistics:\")\n",
        "print(f\"  Min: {min(lengths)}\")\n",
        "print(f\"  Max: {max(lengths)}\")\n",
        "print(f\"  Mean: {sum(lengths)/len(lengths):.1f}\")\n",
        "print(f\"  Median: {sorted(lengths)[len(lengths)//2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Save Processed Data\n",
        "\n",
        "Save processed sequences, vocabulary, and tokenizer config for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved vocabulary to: processed_data\\vocab.json\n",
            "   Size: 746 tokens\n",
            "‚úÖ Saved ID mapping to: processed_data\\id_to_token.json\n",
            "‚úÖ Saved 3,843 sequences to: processed_data\\sequences.json\n",
            "‚úÖ Saved config to: processed_data\\preprocessing_config.json\n",
            "\n",
            "üìä Summary:\n",
            "  Total sequences: 3,843\n",
            "  Total tokens: 7,766,992\n",
            "  Vocabulary size: 746\n",
            "  Output directory: processed_data\n"
          ]
        }
      ],
      "source": [
        "# Save processed data\n",
        "output_dir = CONFIG['output_dir']\n",
        "\n",
        "# 1. Save vocabulary\n",
        "vocab_path = output_dir / \"vocab.json\"\n",
        "with open(vocab_path, 'w') as f:\n",
        "    json.dump(vocab, f, indent=2)\n",
        "print(f\"‚úÖ Saved vocabulary to: {vocab_path}\")\n",
        "print(f\"   Size: {len(vocab):,} tokens\")\n",
        "\n",
        "# 2. Save ID to token mapping\n",
        "id_to_token_path = output_dir / \"id_to_token.json\"\n",
        "with open(id_to_token_path, 'w') as f:\n",
        "    json.dump(id_to_token, f, indent=2)\n",
        "print(f\"‚úÖ Saved ID mapping to: {id_to_token_path}\")\n",
        "\n",
        "# 3. Save tokenized sequences\n",
        "sequences_path = output_dir / \"sequences.json\"\n",
        "sequences_to_save = [\n",
        "    {\n",
        "        'entry_id': s['entry_id'],\n",
        "        'token_ids': s['token_ids'],\n",
        "        'length': s['length']\n",
        "    }\n",
        "    for s in tokenized_sequences\n",
        "]\n",
        "with open(sequences_path, 'w') as f:\n",
        "    json.dump(sequences_to_save, f)\n",
        "print(f\"‚úÖ Saved {len(sequences_to_save):,} sequences to: {sequences_path}\")\n",
        "\n",
        "# 4. Save preprocessing config\n",
        "config_to_save = {\n",
        "    'min_quality_score': CONFIG['min_quality_score'],\n",
        "    'max_sequence_length': CONFIG['max_sequence_length'],\n",
        "    'time_quantization': CONFIG['time_quantization'],\n",
        "    'vocab_size': len(vocab),\n",
        "    'num_sequences': len(sequences_to_save),\n",
        "    'total_tokens': sum(s['length'] for s in sequences_to_save)\n",
        "}\n",
        "config_path = output_dir / \"preprocessing_config.json\"\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config_to_save, f, indent=2)\n",
        "print(f\"‚úÖ Saved config to: {config_path}\")\n",
        "\n",
        "print(f\"\\nüìä Summary:\")\n",
        "print(f\"  Total sequences: {len(sequences_to_save):,}\")\n",
        "print(f\"  Total tokens: {sum(s['length'] for s in sequences_to_save):,}\")\n",
        "print(f\"  Vocabulary size: {len(vocab):,}\")\n",
        "print(f\"  Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Verify Saved Data\n",
        "\n",
        "Load and verify the saved processed data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying saved data...\n",
            "‚úÖ Loaded vocabulary: 746 tokens\n",
            "‚úÖ Loaded sequences: 3,843\n",
            "‚úÖ Loaded config:\n",
            "   min_quality_score: 0.97\n",
            "   max_sequence_length: 2048\n",
            "   time_quantization: 10\n",
            "   vocab_size: 746\n",
            "   num_sequences: 3843\n",
            "   total_tokens: 7766992\n",
            "\n",
            "Sample sequence (ID: 79863):\n",
            "  First 30 tokens: ['START', 'GENRE:pop', 'TIME_SHIFT:2240', 'NOTE_ON:55', 'VELOCITY:45', 'TIME_SHIFT:20', 'NOTE_ON:90', 'VELOCITY:65', 'NOTE_ON:95', 'VELOCITY:70', 'TIME_SHIFT:10', 'NOTE_ON:86', 'VELOCITY:60', 'TIME_SHIFT:300', 'NOTE_ON:62', 'VELOCITY:50', 'TIME_SHIFT:100', 'NOTE_ON:67', 'VELOCITY:55', 'TIME_SHIFT:180', 'NOTE_ON:91', 'VELOCITY:70', 'TIME_SHIFT:10', 'NOTE_ON:83', 'VELOCITY:55', 'NOTE_ON:79', 'VELOCITY:65', 'TIME_SHIFT:320', 'NOTE_ON:71', 'VELOCITY:60']\n",
            "\n",
            "‚úÖ Preprocessing complete! Data ready for training.\n"
          ]
        }
      ],
      "source": [
        "# Verify saved data\n",
        "print(\"Verifying saved data...\")\n",
        "\n",
        "# Load vocabulary\n",
        "with open(vocab_path, 'r') as f:\n",
        "    loaded_vocab = json.load(f)\n",
        "print(f\"‚úÖ Loaded vocabulary: {len(loaded_vocab):,} tokens\")\n",
        "\n",
        "# Load sequences (sample)\n",
        "with open(sequences_path, 'r') as f:\n",
        "    loaded_sequences = json.load(f)\n",
        "print(f\"‚úÖ Loaded sequences: {len(loaded_sequences):,}\")\n",
        "\n",
        "# Load config\n",
        "with open(config_path, 'r') as f:\n",
        "    loaded_config = json.load(f)\n",
        "print(f\"‚úÖ Loaded config:\")\n",
        "for key, value in loaded_config.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Show sample sequence\n",
        "print(f\"\\nSample sequence (ID: {loaded_sequences[0]['entry_id']}):\")\n",
        "sample_ids = loaded_sequences[0]['token_ids'][:30]\n",
        "sample_tokens = [id_to_token[tid] for tid in sample_ids]\n",
        "print(f\"  First 30 tokens: {sample_tokens}\")\n",
        "\n",
        "print(\"\\n‚úÖ Preprocessing complete! Data ready for training.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
