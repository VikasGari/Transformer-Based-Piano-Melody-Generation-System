{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piano MIDI Generation - Inference\n",
    "\n",
    "This notebook generates MIDI files from the trained model using metadata conditions.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Load model and vocabulary** - From checkpoint and processed data\n",
    "2. **Setup tokenizers** - For metadata and MIDI conversion\n",
    "3. **Generate MIDI tokens** - Autoregressive generation from metadata\n",
    "4. **Convert tokens to MIDI** - Reverse tokenization to MIDI format\n",
    "5. **Save MIDI file** - Export as .mid for DAW import\n",
    "\n",
    "## Usage\n",
    "\n",
    "Set your desired metadata (genre, composer, period) and run the generation cell.\n",
    "The output MIDI file can be imported into FL Studio or any other DAW.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model classes imported from model.py\n",
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Optional, Dict\n",
    "import mido\n",
    "from datetime import datetime\n",
    "\n",
    "# Import model architecture\n",
    "try:\n",
    "    from model import PianoMIDIGenerator, PositionalEncoding, TransformerBlock\n",
    "    print(\"‚úÖ Model classes imported from model.py\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Could not import from model.py\")\n",
    "    print(\"   Please ensure model.py exists in the same directory\")\n",
    "    raise\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Model and Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded vocabulary: 746 tokens\n",
      "   Pad token ID: 0\n",
      "   Start token ID: 2\n",
      "   End token ID: 3\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"processed_data\")\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "OUTPUT_DIR = Path(\"generated_midi\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load vocabulary\n",
    "with open(DATA_DIR / \"vocab.json\", 'r') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "with open(DATA_DIR / \"id_to_token.json\", 'r') as f:\n",
    "    id_to_token = json.load(f)\n",
    "    # Convert keys to int\n",
    "    id_to_token = {int(k): v for k, v in id_to_token.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "pad_token_id = vocab.get('<PAD>', 0)\n",
    "start_token_id = vocab.get('<START>', 2)\n",
    "end_token_id = vocab.get('<END>', 3)\n",
    "\n",
    "print(f\"‚úÖ Loaded vocabulary: {vocab_size:,} tokens\")\n",
    "print(f\"   Pad token ID: {pad_token_id}\")\n",
    "print(f\"   Start token ID: {start_token_id}\")\n",
    "print(f\"   End token ID: {end_token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model config loaded:\n",
      "   Vocab size: 746\n",
      "   Max sequence length: 2048\n"
     ]
    }
   ],
   "source": [
    "# Load model configuration\n",
    "with open(DATA_DIR / \"preprocessing_config.json\", 'r') as f:\n",
    "    preprocess_config = json.load(f)\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'max_seq_length': preprocess_config['max_sequence_length'],\n",
    "    'd_model': 512,\n",
    "    'n_layers': 6,\n",
    "    'n_heads': 8,\n",
    "    'd_ff': 2048,\n",
    "    'dropout': 0.0,  # No dropout during inference\n",
    "    'pad_token_id': pad_token_id,\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Model config loaded:\")\n",
    "print(f\"   Vocab size: {MODEL_CONFIG['vocab_size']}\")\n",
    "print(f\"   Max sequence length: {MODEL_CONFIG['max_seq_length']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: cpu\n",
      "üìÇ Loading checkpoint: checkpoints\\checkpoint_best.pt\n",
      "‚úÖ Model loaded from checkpoint:\n",
      "   Epoch: 8\n",
      "   Step: 11,900\n",
      "   Validation loss: 2.4088\n",
      "   Model parameters: 19.7M\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "device = torch.device('cpu')\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# Load model checkpoint\n",
    "checkpoint_path = CHECKPOINT_DIR / 'checkpoint_best.pt'\n",
    "\n",
    "if not checkpoint_path.exists():\n",
    "    print(f\"‚ö†Ô∏è  Best checkpoint not found at {checkpoint_path}\")\n",
    "    print(f\"   Available checkpoints:\")\n",
    "    for cp in CHECKPOINT_DIR.glob('*.pt'):\n",
    "        print(f\"     - {cp.name}\")\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "print(f\"üìÇ Loading checkpoint: {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Create model\n",
    "model = PianoMIDIGenerator(MODEL_CONFIG)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"‚úÖ Model loaded from checkpoint:\")\n",
    "print(f\"   Epoch: {checkpoint['epoch'] + 1}\")\n",
    "print(f\"   Step: {checkpoint['step']:,}\")\n",
    "print(f\"   Validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.1f}M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata tokenizer created\n"
     ]
    }
   ],
   "source": [
    "# Metadata tokenizer (same as preprocessing)\n",
    "class MetadataTokenizer:\n",
    "    def __init__(self, include_composer=True, top_n_composers=100):\n",
    "        self.include_composer = include_composer\n",
    "        self.valid_genres = {'classical', 'pop', 'soundtrack', 'jazz', 'rock', 'folk', 'ambient', 'ragtime', 'blues', 'atonal'}\n",
    "        self.valid_periods = {'contemporary', 'modern', 'romantic', 'classical', 'baroque', 'impressionist'}\n",
    "        self.top_composers = self._load_top_composers(top_n_composers)\n",
    "    \n",
    "    def _load_top_composers(self, n):\n",
    "        top = {'hisaishi', 'satie', 'yiruma', 'einaudi', 'joplin', 'chopin', 'beethoven', 'bach', 'mozart', 'debussy',\n",
    "               'schubert', 'schumann', 'liszt', 'rachmaninoff', 'tchaikovsky', 'ravel', 'poulenc', 'faure', 'bartok'}\n",
    "        return {self._normalize_composer(c) for c in top}\n",
    "    \n",
    "    def _normalize_composer(self, composer):\n",
    "        if not composer:\n",
    "            return \"\"\n",
    "        normalized = composer.lower().strip()\n",
    "        normalized = normalized.replace('√©', 'e').replace('√®', 'e').replace('√°', 'a').replace('√†', 'a')\n",
    "        normalized = normalized.replace('√≠', 'i').replace('√¨', 'i').replace('√≥', 'o').replace('√≤', 'o')\n",
    "        normalized = normalized.replace('√∫', 'u').replace('√π', 'u').replace('√±', 'n')\n",
    "        normalized = re.sub(r'[^a-z0-9\\s-]', '', normalized)\n",
    "        normalized = re.sub(r'\\s+', ' ', normalized).strip()\n",
    "        return normalized\n",
    "    \n",
    "    def metadata_to_tokens(self, metadata, include_start=True):\n",
    "        tokens = []\n",
    "        if include_start:\n",
    "            tokens.append(\"START\")\n",
    "        \n",
    "        if metadata.get('genre'):\n",
    "            genre = metadata['genre'].lower().strip()\n",
    "            if genre in self.valid_genres:\n",
    "                tokens.append(f\"GENRE:{genre}\")\n",
    "        \n",
    "        if metadata.get('music_period'):\n",
    "            period = metadata['music_period'].lower().strip()\n",
    "            if period in self.valid_periods:\n",
    "                tokens.append(f\"PERIOD:{period}\")\n",
    "        \n",
    "        if self.include_composer and metadata.get('composer'):\n",
    "            composer = self._normalize_composer(metadata['composer'])\n",
    "            if composer in self.top_composers:\n",
    "                tokens.append(f\"COMPOSER:{composer}\")\n",
    "        \n",
    "        return tokens\n",
    "\n",
    "meta_tokenizer = MetadataTokenizer(include_composer=True)\n",
    "print(\"‚úÖ Metadata tokenizer created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MIDI tokenizer created\n"
     ]
    }
   ],
   "source": [
    "# MIDI tokenizer (reverse conversion)\n",
    "class MIDITokenizer:\n",
    "    def __init__(self, time_quantization=10):\n",
    "        self.time_quantization = time_quantization\n",
    "    \n",
    "    def tokens_to_midi(self, tokens: List[str], output_path: Path, tempo=120, ticks_per_beat=480):\n",
    "        \"\"\"\n",
    "        Convert tokens back to MIDI file\n",
    "        \n",
    "        Args:\n",
    "            tokens: List of token strings\n",
    "            output_path: Path to save MIDI file\n",
    "            tempo: Tempo in BPM\n",
    "            ticks_per_beat: MIDI ticks per quarter note (default 480)\n",
    "                           IMPORTANT: Must match the ticks_per_beat of original MIDI files\n",
    "                           to preserve correct timing. Try 480, 960, or 384 if timing is off.\n",
    "        \"\"\"\n",
    "        mid = mido.MidiFile(ticks_per_beat=ticks_per_beat)\n",
    "        track = mido.MidiTrack()\n",
    "        mid.tracks.append(track)\n",
    "        \n",
    "        # Set tempo (microseconds per quarter note)\n",
    "        tempo_us = mido.bpm2tempo(tempo)\n",
    "        track.append(mido.MetaMessage('set_tempo', tempo=tempo_us))\n",
    "        \n",
    "        # IMPORTANT: TIME_SHIFT values represent quantized MIDI ticks from the original files\n",
    "        # The preprocessing: quantized_time = (current_time // time_quantization) * time_quantization\n",
    "        # where current_time is accumulated from msg.time (which is in ticks from original MIDI)\n",
    "        # So TIME_SHIFT:1280 means 1280 ticks from the ORIGINAL file's ticks_per_beat\n",
    "        # If original had 960 ticks_per_beat and we use 480, timing will be compressed by 2x!\n",
    "        # We use these tick values directly, assuming ticks_per_beat matches the original\n",
    "        \n",
    "        current_time_ticks = 0  # Accumulate time in MIDI ticks\n",
    "        pending_note_on = None  # (note, velocity, start_time)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            \n",
    "            # Skip metadata and control tokens\n",
    "            if token.startswith('START') or token.startswith('GENRE:') or token.startswith('PERIOD:') or token.startswith('COMPOSER:') or token in ['<END>', '<PAD>', '<UNK>']:\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Parse TIME_SHIFT (value is in MIDI ticks, already quantized)\n",
    "            # Handle TIME_SHIFT: accumulate consecutive TIME_SHIFT tokens until we hit a note event\n",
    "            # This handles cases where model generates multiple TIME_SHIFT tokens\n",
    "            if token.startswith('TIME_SHIFT:'):\n",
    "                # Accumulate all consecutive TIME_SHIFT tokens\n",
    "                accumulated_ticks = 0\n",
    "                while i < len(tokens) and tokens[i].startswith('TIME_SHIFT:'):\n",
    "                    time_ticks = int(tokens[i].split(':')[1])\n",
    "                    accumulated_ticks += time_ticks\n",
    "                    i += 1\n",
    "                current_time_ticks = accumulated_ticks\n",
    "                continue  # Continue to process the next token (should be a note event)\n",
    "            # Parse NOTE_ON\n",
    "            elif token.startswith('NOTE_ON:'):\n",
    "                note = int(token.split(':')[1])\n",
    "                velocity = 64  # Default velocity\n",
    "                \n",
    "                # Check if next token is VELOCITY\n",
    "                if i + 1 < len(tokens) and tokens[i + 1].startswith('VELOCITY:'):\n",
    "                    velocity = int(tokens[i + 1].split(':')[1])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    i += 1\n",
    "                \n",
    "                # TIME_SHIFT values are already in MIDI ticks, use directly\n",
    "                track.append(mido.Message('note_on', channel=0, note=note, velocity=velocity, time=current_time_ticks))\n",
    "                current_time_ticks = 0  # Reset accumulated time\n",
    "                pending_note_on = (note, velocity)\n",
    "            \n",
    "            # Parse NOTE_OFF\n",
    "            elif token.startswith('NOTE_OFF:'):\n",
    "                note = int(token.split(':')[1])\n",
    "                \n",
    "                # TIME_SHIFT values are already in MIDI ticks, use directly\n",
    "                track.append(mido.Message('note_off', channel=0, note=note, velocity=0, time=current_time_ticks))\n",
    "                current_time_ticks = 0  # Reset accumulated time\n",
    "                i += 1\n",
    "            \n",
    "            # Parse VELOCITY (standalone - should not happen in proper sequence)\n",
    "            elif token.startswith('VELOCITY:'):\n",
    "                i += 1\n",
    "                continue\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        mid.save(output_path)\n",
    "        return mid\n",
    "\n",
    "midi_tokenizer = MIDITokenizer(time_quantization=10)\n",
    "print(\"‚úÖ MIDI tokenizer created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generation function defined\n"
     ]
    }
   ],
   "source": [
    "def generate_midi(\n",
    "    model,\n",
    "    vocab,\n",
    "    id_to_token,\n",
    "    meta_tokenizer,\n",
    "    metadata: Dict[str, str],\n",
    "    max_length: int = 1024,\n",
    "    min_length: int = 500,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: Optional[int] = 50,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate MIDI tokens from metadata conditions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PianoMIDIGenerator model\n",
    "        vocab: Token to ID mapping\n",
    "        id_to_token: ID to token mapping\n",
    "        meta_tokenizer: MetadataTokenizer instance\n",
    "        metadata: Dictionary with 'genre', 'composer', 'music_period' keys\n",
    "        max_length: Maximum generation length\n",
    "        min_length: Minimum generation length before allowing early stop\n",
    "        temperature: Sampling temperature (higher = more random)\n",
    "        top_k: Top-k sampling (None = no filtering)\n",
    "        device: Device to run generation on\n",
    "    \n",
    "    Returns:\n",
    "        List of generated tokens\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert metadata to tokens\n",
    "    metadata_tokens = meta_tokenizer.metadata_to_tokens(metadata, include_start=True)\n",
    "    print(f\"üìù Metadata tokens: {metadata_tokens}\")\n",
    "    \n",
    "    # Convert metadata tokens to IDs\n",
    "    input_ids = [vocab.get(token, vocab.get('<UNK>', 1)) for token in metadata_tokens]\n",
    "    \n",
    "    # Generation loop\n",
    "    generated_tokens = metadata_tokens.copy()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while len(generated_tokens) < max_length:\n",
    "            # Prepare input (limit to max_seq_length)\n",
    "            current_input = input_ids[-MODEL_CONFIG['max_seq_length']:] if len(input_ids) > MODEL_CONFIG['max_seq_length'] else input_ids\n",
    "            input_tensor = torch.tensor([current_input], dtype=torch.long, device=device)\n",
    "            attention_mask = torch.ones_like(input_tensor, dtype=torch.long)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_tensor, attention_mask=attention_mask)\n",
    "            \n",
    "            # Get logits for last position\n",
    "            next_token_logits = logits[0, -1, :] / temperature\n",
    "            \n",
    "            # Apply top-k filtering\n",
    "            if top_k is not None:\n",
    "                top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                # Create filtered logits\n",
    "                filtered_logits = torch.full_like(next_token_logits, float('-inf'))\n",
    "                filtered_logits[top_k_indices] = top_k_logits\n",
    "                next_token_logits = filtered_logits\n",
    "            \n",
    "            # Sample from distribution\n",
    "            probs = torch.softmax(next_token_logits, dim=-1)\n",
    "            next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            # Convert to token\n",
    "            next_token = id_to_token.get(next_token_id, '<UNK>')\n",
    "            generated_tokens.append(next_token)\n",
    "            input_ids.append(next_token_id)\n",
    "            \n",
    "            # Stop if end token (only if we've reached minimum length)\n",
    "            if (next_token == '<END>' or next_token_id == vocab.get('<END>', 3)) and len(generated_tokens) >= min_length:\n",
    "                print(f\"   Reached <END> token at {len(generated_tokens)} tokens (min: {min_length})\")\n",
    "                break\n",
    "            \n",
    "            # Prevent infinite loops\n",
    "            if len(generated_tokens) % 100 == 0:\n",
    "                print(f\"   Generated {len(generated_tokens)} tokens...\", end='\\r')\n",
    "    \n",
    "    print()  # New line after progress\n",
    "    return generated_tokens\n",
    "\n",
    "print(\"‚úÖ Generation function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate MIDI File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generation Configuration:\n",
      "   Metadata: {'genre': 'classical', 'composer': 'chopin', 'music_period': 'romantic'}\n",
      "   Max length: 2000\n",
      "   Min length: 1500\n",
      "   Temperature: 0.8\n",
      "   Top-k: 50\n",
      "   Tempo: 120 BPM\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# GENERATION CONFIGURATION\n",
    "# ============================================\n",
    "# Modify these values to change generation settings\n",
    "\n",
    "METADATA = {\n",
    "    'genre': 'classical',  # Options: 'classical', 'pop', 'jazz', 'soundtrack', 'rock', 'folk', 'ambient', etc.\n",
    "    'composer': 'chopin',  # Options: 'chopin', 'beethoven', 'bach', 'mozart', 'debussy', 'yiruma', 'einaudi', etc. (or None)\n",
    "    'music_period': 'romantic',  # Options: 'romantic', 'classical', 'baroque', 'contemporary', 'modern', 'impressionist' (or None)\n",
    "}\n",
    "\n",
    "GENERATION_CONFIG = {\n",
    "    'max_length': 2000,  # Maximum number of tokens to generate (matches training sequence length ~1-2 minutes)\n",
    "    'temperature': 0.8,  # Lower = more deterministic, Higher = more creative (0.5-1.5 range)\n",
    "    'top_k': 50,  # Top-k sampling: only sample from top K most likely tokens (None to disable)\n",
    "    'tempo': 120,  # MIDI tempo (BPM)\n",
    "    'min_length': 1500,  # Minimum tokens to generate before allowing early stop (ensures ~1 min minimum)\n",
    "}\n",
    "\n",
    "print(\"üìù Generation Configuration:\")\n",
    "print(f\"   Metadata: {METADATA}\")\n",
    "print(f\"   Max length: {GENERATION_CONFIG['max_length']}\")\n",
    "print(f\"   Min length: {GENERATION_CONFIG.get('min_length', 500)}\")\n",
    "print(f\"   Temperature: {GENERATION_CONFIG['temperature']}\")\n",
    "print(f\"   Top-k: {GENERATION_CONFIG['top_k']}\")\n",
    "print(f\"   Tempo: {GENERATION_CONFIG['tempo']} BPM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéπ Generating MIDI tokens...\n",
      "============================================================\n",
      "üìù Metadata tokens: ['START', 'GENRE:classical', 'PERIOD:romantic', 'COMPOSER:chopin']\n",
      "   Generated 2000 tokens...\n",
      "\n",
      "‚úÖ Generated 2000 tokens\n",
      "\n",
      "First 50 tokens: ['START', 'GENRE:classical', 'PERIOD:romantic', 'COMPOSER:chopin', 'TIME_SHIFT:390', 'NOTE_ON:72', 'VELOCITY:65', 'TIME_SHIFT:30', 'NOTE_OFF:72', 'TIME_SHIFT:20', 'NOTE_OFF:72', 'TIME_SHIFT:10', 'NOTE_ON:48', 'VELOCITY:45', 'NOTE_ON:60', 'VELOCITY:65', 'NOTE_ON:72', 'VELOCITY:75', 'TIME_SHIFT:10', 'NOTE_ON:63', 'VELOCITY:60', 'TIME_SHIFT:20', 'NOTE_OFF:60', 'TIME_SHIFT:10', 'NOTE_OFF:48', 'TIME_SHIFT:10', 'NOTE_OFF:63', 'TIME_SHIFT:70', 'NOTE_OFF:67', 'TIME_SHIFT:60', 'NOTE_ON:77', 'VELOCITY:85', 'TIME_SHIFT:10', 'NOTE_ON:56', 'VELOCITY:75', 'TIME_SHIFT:10', 'NOTE_ON:65', 'VELOCITY:75', 'TIME_SHIFT:20', 'NOTE_OFF:75', 'NOTE_OFF:70', 'TIME_SHIFT:10', 'NOTE_OFF:56', 'TIME_SHIFT:100', 'NOTE_ON:75', 'VELOCITY:90', 'TIME_SHIFT:10', 'NOTE_ON:75', 'VELOCITY:85', 'TIME_SHIFT:10']\n",
      "\n",
      "üìä MIDI tokens (filtered): 1996 tokens\n",
      "\n",
      "First 30 MIDI tokens: ['TIME_SHIFT:390', 'NOTE_ON:72', 'VELOCITY:65', 'TIME_SHIFT:30', 'NOTE_OFF:72', 'TIME_SHIFT:20', 'NOTE_OFF:72', 'TIME_SHIFT:10', 'NOTE_ON:48', 'VELOCITY:45', 'NOTE_ON:60', 'VELOCITY:65', 'NOTE_ON:72', 'VELOCITY:75', 'TIME_SHIFT:10', 'NOTE_ON:63', 'VELOCITY:60', 'TIME_SHIFT:20', 'NOTE_OFF:60', 'TIME_SHIFT:10', 'NOTE_OFF:48', 'TIME_SHIFT:10', 'NOTE_OFF:63', 'TIME_SHIFT:70', 'NOTE_OFF:67', 'TIME_SHIFT:60', 'NOTE_ON:77', 'VELOCITY:85', 'TIME_SHIFT:10', 'NOTE_ON:56']\n"
     ]
    }
   ],
   "source": [
    "# Generate tokens\n",
    "print(\"\\nüéπ Generating MIDI tokens...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "generated_tokens = generate_midi(\n",
    "    model=model,\n",
    "    vocab=vocab,\n",
    "    id_to_token=id_to_token,\n",
    "    meta_tokenizer=meta_tokenizer,\n",
    "    metadata=METADATA,\n",
    "    max_length=GENERATION_CONFIG['max_length'],\n",
    "    min_length=GENERATION_CONFIG.get('min_length', 500),\n",
    "    temperature=GENERATION_CONFIG['temperature'],\n",
    "    top_k=GENERATION_CONFIG['top_k'],\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Generated {len(generated_tokens)} tokens\")\n",
    "print(f\"\\nFirst 50 tokens: {generated_tokens[:50]}\")\n",
    "\n",
    "# Filter out metadata tokens for MIDI conversion\n",
    "midi_tokens = [\n",
    "    token for token in generated_tokens \n",
    "    if not (token.startswith('START') or token.startswith('GENRE:') or \n",
    "            token.startswith('PERIOD:') or token.startswith('COMPOSER:') or \n",
    "            token in ['<END>', '<PAD>', '<UNK>'])\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä MIDI tokens (filtered): {len(midi_tokens)} tokens\")\n",
    "print(f\"\\nFirst 30 MIDI tokens: {midi_tokens[:30]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéµ Converting tokens to MIDI file...\n",
      "\n",
      "‚úÖ MIDI file saved: generated_midi\\generated_classical_chopin_20251103_110342.mid\n",
      "   File size: 2.62 KB\n",
      "\n",
      "üìÅ You can now import this file into FL Studio or any DAW!\n"
     ]
    }
   ],
   "source": [
    "# Convert tokens to MIDI and save\n",
    "print(\"\\nüéµ Converting tokens to MIDI file...\")\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "genre_str = METADATA.get('genre', 'unknown')\n",
    "composer_str = METADATA.get('composer', 'unknown')\n",
    "filename = f\"generated_{genre_str}_{composer_str}_{timestamp}.mid\"\n",
    "output_path = OUTPUT_DIR / filename\n",
    "\n",
    "# Convert and save\n",
    "# IMPORTANT: Original MIDI files use ticks_per_beat=500\n",
    "# TIME_SHIFT values are quantized MIDI ticks from files with ticks_per_beat=500\n",
    "# We must use ticks_per_beat=500 to preserve correct timing!\n",
    "midi_tokenizer.tokens_to_midi(\n",
    "    tokens=midi_tokens,\n",
    "    output_path=output_path,\n",
    "    tempo=GENERATION_CONFIG['tempo'],\n",
    "    ticks_per_beat=500  # MUST match original files' ticks_per_beat (verified: all files use 500)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ MIDI file saved: {output_path}\")\n",
    "print(f\"   File size: {output_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"\\nüìÅ You can now import this file into FL Studio or any DAW!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Timing Analysis:\n",
      "   Total TIME_SHIFT ticks: 18,990\n",
      "   Number of MIDI events: 797\n",
      "   At 240 ticks_per_beat: 39.6s (0.66 min)\n",
      "   At 384 ticks_per_beat: 24.7s (0.41 min)\n",
      "   At 480 ticks_per_beat: 19.8s (0.33 min)\n",
      "   At 500 ticks_per_beat: 19.0s (0.32 min) ‚≠ê CORRECT (matches original files)\n",
      "   At 960 ticks_per_beat: 9.9s (0.16 min)\n",
      "\n",
      "üí° Original MIDI files use ticks_per_beat=500\n",
      "   Use ticks_per_beat=500 for correct timing (already set in generation cell above)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# TIMING DIAGNOSTIC\n",
    "# ============================================\n",
    "# If your generated MIDI is too fast/slow, try different ticks_per_beat values\n",
    "# This cell helps you test different values\n",
    "\n",
    "# Calculate total time from TIME_SHIFT tokens\n",
    "total_time_ticks = 0\n",
    "for token in midi_tokens:\n",
    "    if token.startswith('TIME_SHIFT:'):\n",
    "        total_time_ticks += int(token.split(':')[1])\n",
    "\n",
    "print(f\"üìä Timing Analysis:\")\n",
    "print(f\"   Total TIME_SHIFT ticks: {total_time_ticks:,}\")\n",
    "print(f\"   Number of MIDI events: {len([t for t in midi_tokens if t.startswith('NOTE_ON') or t.startswith('NOTE_OFF')])}\")\n",
    "\n",
    "# Calculate duration at different ticks_per_beat values\n",
    "# Original files use ticks_per_beat=500, so that should give correct timing\n",
    "for tpb in [240, 384, 480, 500, 960]:\n",
    "    # At tempo BPM, beats per second = tempo/60\n",
    "    # ticks per second = ticks_per_beat * beats_per_second\n",
    "    # duration = total_ticks / ticks_per_second\n",
    "    tempo = GENERATION_CONFIG['tempo']\n",
    "    ticks_per_second = tpb * tempo / 60\n",
    "    duration_seconds = total_time_ticks / ticks_per_second\n",
    "    duration_minutes = duration_seconds / 60\n",
    "    \n",
    "    marker = \" ‚≠ê CORRECT (matches original files)\" if tpb == 500 else \"\"\n",
    "    print(f\"   At {tpb} ticks_per_beat: {duration_seconds:.1f}s ({duration_minutes:.2f} min){marker}\")\n",
    "\n",
    "print(f\"\\nüí° Original MIDI files use ticks_per_beat=500\")\n",
    "print(f\"   Use ticks_per_beat=500 for correct timing (already set in generation cell above)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Convert MIDI to WAV using Soundfonts\n",
    "\n",
    "Convert the generated MIDI file to WAV audio using one of the available soundfonts (SF2 files).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found fluidsynth at custom path: C:\\Users\\Vikas Gari\\Downloads\\fluidsynth-v2.5.1-win10-x64-cpp11\\fluidsynth-v2.5.1-win10-x64-cpp11\\bin\\fluidsynth.exe\n",
      "   Version: FluidSynth runtime version 2.5.1\n",
      "Copyright (C) 2000-2025 Peter Hanappe and others.\n",
      "Distributed under the LGPL license.\n",
      "SoundFont(R) is a registered trademark of Creative Technology Ltd.\n",
      "\n",
      "FluidSynth executable version 2.5.1\n",
      "Sample type=float\n",
      "‚úÖ Audio conversion setup complete\n"
     ]
    }
   ],
   "source": [
    "# Import audio processing libraries\n",
    "import subprocess\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Custom fluidsynth path (Windows)\n",
    "CUSTOM_FLUIDSYNTH_PATH = r\"C:\\Users\\Vikas Gari\\Downloads\\fluidsynth-v2.5.1-win10-x64-cpp11\\fluidsynth-v2.5.1-win10-x64-cpp11\\bin\"\n",
    "FLUIDSYNTH_EXE = os.path.join(CUSTOM_FLUIDSYNTH_PATH, \"fluidsynth.exe\")\n",
    "\n",
    "# Global flags for fluidsynth availability\n",
    "USE_FLUIDSYNTH_LIB = False\n",
    "USE_FLUIDSYNTH_CMD = False\n",
    "FLUIDSYNTH_CMD = None  # Will be set to the command to use\n",
    "\n",
    "# Try to use pyfluidsynth library if available\n",
    "try:\n",
    "    import fluidsynth\n",
    "    USE_FLUIDSYNTH_LIB = True\n",
    "    print(\"‚úÖ Found fluidsynth Python library\")\n",
    "except ImportError:\n",
    "    USE_FLUIDSYNTH_LIB = False\n",
    "\n",
    "# Check custom path first, then system PATH\n",
    "fluidsynth_found = False\n",
    "\n",
    "# Check custom path\n",
    "if os.path.exists(FLUIDSYNTH_EXE):\n",
    "    FLUIDSYNTH_CMD = FLUIDSYNTH_EXE\n",
    "    try:\n",
    "        result = subprocess.run([FLUIDSYNTH_CMD, '--version'], capture_output=True, text=True, timeout=2)\n",
    "        if result.returncode == 0:\n",
    "            USE_FLUIDSYNTH_CMD = True\n",
    "            fluidsynth_found = True\n",
    "            print(f\"‚úÖ Found fluidsynth at custom path: {FLUIDSYNTH_CMD}\")\n",
    "            print(f\"   Version: {result.stdout.strip()}\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "# If not found in custom path, check system PATH\n",
    "if not fluidsynth_found:\n",
    "    try:\n",
    "        result = subprocess.run(['fluidsynth', '--version'], capture_output=True, text=True, timeout=2)\n",
    "        if result.returncode == 0:\n",
    "            USE_FLUIDSYNTH_CMD = True\n",
    "            FLUIDSYNTH_CMD = 'fluidsynth'\n",
    "            fluidsynth_found = True\n",
    "            print(\"‚úÖ Found fluidsynth in system PATH\")\n",
    "            print(f\"   Version: {result.stdout.strip()}\")\n",
    "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "        pass\n",
    "\n",
    "if not USE_FLUIDSYNTH_LIB and not USE_FLUIDSYNTH_CMD:\n",
    "    print(\"‚ö†Ô∏è  fluidsynth not found. Options:\")\n",
    "    print(\"   1. Install Python library: pip install pyfluidsynth\")\n",
    "    print(\"   2. Add fluidsynth to system PATH\")\n",
    "    print(f\"   3. Update CUSTOM_FLUIDSYNTH_PATH in this cell if your path is different\")\n",
    "    print(f\"   Current custom path: {CUSTOM_FLUIDSYNTH_PATH}\")\n",
    "else:\n",
    "    print(\"‚úÖ Audio conversion setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1000 soundfont files\n",
      "\n",
      "First 10 soundfonts:\n",
      "   1. 16-Bit_Game_Station.sf2\n",
      "   2. 16-Bit_Game_Station.sf2\n",
      "   3. 2MBGMGSMT.sf2\n",
      "   4. 2MBGMGSMT.sf2\n",
      "   5. 32MbGMStereo.sf2\n",
      "   6. 32MbGMStereo.sf2\n",
      "   7. 4MBGM_Plus12.sf2\n",
      "   8. 4MBGM_Plus12.sf2\n",
      "   9. 4MBGMGSMT.sf2\n",
      "   10. 4MBGMGSMT.sf2\n",
      "   ... and 990 more\n",
      "\n",
      "üí° You can select a specific soundfont or use 'random' to pick one automatically\n"
     ]
    }
   ],
   "source": [
    "# List available soundfonts\n",
    "SOUNDFONT_DIR = Path(\"sound_fonts\")\n",
    "WAV_OUTPUT_DIR = OUTPUT_DIR  # Save WAV files alongside MIDI files\n",
    "\n",
    "soundfont_files = sorted(list(SOUNDFONT_DIR.glob(\"*.sf2\")) + list(SOUNDFONT_DIR.glob(\"*.SF2\")))\n",
    "\n",
    "if not soundfont_files:\n",
    "    print(\"‚ö†Ô∏è  No soundfont files found in sound_fonts/ directory\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(soundfont_files)} soundfont files\")\n",
    "    print(f\"\\nFirst 10 soundfonts:\")\n",
    "    for i, sf in enumerate(soundfont_files[:10], 1):\n",
    "        print(f\"   {i}. {sf.name}\")\n",
    "    if len(soundfont_files) > 10:\n",
    "        print(f\"   ... and {len(soundfont_files) - 10} more\")\n",
    "    \n",
    "    print(f\"\\nüí° You can select a specific soundfont or use 'random' to pick one automatically\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéπ Randomly selected soundfont: General_MIDI_64_1.6.sf2\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SOUNDFONT SELECTION\n",
    "# ============================================\n",
    "# Choose a soundfont to use for MIDI to WAV conversion\n",
    "# Options:\n",
    "# - 'random': Randomly select from available soundfonts\n",
    "# - Integer index: Use soundfont at that index (0-based)\n",
    "# - String name: Use soundfont with that exact filename\n",
    "# - None: Skip WAV generation\n",
    "\n",
    "SOUNDFONT_SELECTION = 'random'  # Change this to select a specific soundfont\n",
    "# SOUNDFONT_SELECTION = 0  # Use first soundfont\n",
    "# SOUNDFONT_SELECTION = 'FluidR3_GM.sf2'  # Use specific soundfont by name\n",
    "# SOUNDFONT_SELECTION = None  # Skip WAV generation\n",
    "\n",
    "if soundfont_files and SOUNDFONT_SELECTION is not None:\n",
    "    if SOUNDFONT_SELECTION == 'random':\n",
    "        selected_soundfont = random.choice(soundfont_files)\n",
    "        print(f\"üéπ Randomly selected soundfont: {selected_soundfont.name}\")\n",
    "    elif isinstance(SOUNDFONT_SELECTION, int):\n",
    "        if 0 <= SOUNDFONT_SELECTION < len(soundfont_files):\n",
    "            selected_soundfont = soundfont_files[SOUNDFONT_SELECTION]\n",
    "            print(f\"üéπ Selected soundfont (index {SOUNDFONT_SELECTION}): {selected_soundfont.name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Invalid index {SOUNDFONT_SELECTION}. Using random instead.\")\n",
    "            selected_soundfont = random.choice(soundfont_files)\n",
    "            print(f\"   Using: {selected_soundfont.name}\")\n",
    "    elif isinstance(SOUNDFONT_SELECTION, str):\n",
    "        # Find by name\n",
    "        found = None\n",
    "        for sf in soundfont_files:\n",
    "            if sf.name.lower() == SOUNDFONT_SELECTION.lower():\n",
    "                found = sf\n",
    "                break\n",
    "        if found:\n",
    "            selected_soundfont = found\n",
    "            print(f\"üéπ Selected soundfont: {selected_soundfont.name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Soundfont '{SOUNDFONT_SELECTION}' not found. Using random instead.\")\n",
    "            selected_soundfont = random.choice(soundfont_files)\n",
    "            print(f\"   Using: {selected_soundfont.name}\")\n",
    "    else:\n",
    "        selected_soundfont = None\n",
    "        print(\"‚ö†Ô∏è  Invalid SOUNDFONT_SELECTION. Skipping WAV generation.\")\n",
    "else:\n",
    "    selected_soundfont = None\n",
    "    if not soundfont_files:\n",
    "        print(\"‚ö†Ô∏è  No soundfonts available. Skipping WAV generation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WAV conversion function defined\n"
     ]
    }
   ],
   "source": [
    "def midi_to_wav(midi_path: Path, soundfont_path: Path, wav_output_path: Path, sample_rate=44100):\n",
    "    \"\"\"\n",
    "    Convert MIDI file to WAV using a soundfont.\n",
    "    \n",
    "    Args:\n",
    "        midi_path: Path to input MIDI file\n",
    "        soundfont_path: Path to SF2 soundfont file\n",
    "        wav_output_path: Path to output WAV file\n",
    "        sample_rate: Audio sample rate (default 44100 Hz)\n",
    "    \n",
    "    Returns:\n",
    "        True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    # Try command-line first (most reliable)\n",
    "    if USE_FLUIDSYNTH_CMD and FLUIDSYNTH_CMD:\n",
    "        try:\n",
    "            # Using fluidsynth command-line tool\n",
    "            # Command: fluidsynth -a file -F output.wav soundfont.sf2 input.mid\n",
    "            cmd = [\n",
    "                FLUIDSYNTH_CMD,\n",
    "                '-a', 'file',  # Audio driver: file (write to WAV)\n",
    "                '-F', str(wav_output_path),  # Output file\n",
    "                '-r', str(sample_rate),  # Sample rate\n",
    "                str(soundfont_path),  # Soundfont file\n",
    "                str(midi_path)  # MIDI file\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  fluidsynth error: {result.stderr}\")\n",
    "                if result.stdout:\n",
    "                    print(f\"   Output: {result.stdout}\")\n",
    "                return False\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ö†Ô∏è  fluidsynth not found at: {FLUIDSYNTH_CMD}\")\n",
    "            print(f\"   Please check the CUSTOM_FLUIDSYNTH_PATH in the setup cell\")\n",
    "            return False\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"‚ö†Ô∏è  fluidsynth conversion timed out (took longer than 5 minutes)\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error running fluidsynth: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # Try Python library as fallback (if available)\n",
    "    if USE_FLUIDSYNTH_LIB:\n",
    "        try:\n",
    "            import fluidsynth\n",
    "            import numpy as np\n",
    "            \n",
    "            # Initialize synthesizer\n",
    "            fs = fluidsynth.Synth(samplerate=float(sample_rate))\n",
    "            sfid = fs.sfload(str(soundfont_path))\n",
    "            fs.program_select(0, sfid, 0, 0)\n",
    "            fs.start()\n",
    "            \n",
    "            # Read MIDI file and process events\n",
    "            mid = mido.MidiFile(midi_path)\n",
    "            sample_rate = float(sample_rate)\n",
    "            total_time = mid.length  # Duration in seconds\n",
    "            total_samples = int(total_time * sample_rate)\n",
    "            \n",
    "            # Create audio buffer\n",
    "            samples = np.zeros((total_samples, 2), dtype=np.float32)\n",
    "            \n",
    "            # Process MIDI events\n",
    "            current_time = 0.0\n",
    "            for msg in mid:\n",
    "                current_time += msg.time\n",
    "                sample_idx = int(current_time * sample_rate)\n",
    "                \n",
    "                if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                    fs.noteon(msg.channel if hasattr(msg, 'channel') else 0, msg.note, msg.velocity)\n",
    "                elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                    fs.noteoff(msg.channel if hasattr(msg, 'channel') else 0, msg.note)\n",
    "                elif msg.type == 'program_change':\n",
    "                    fs.program_select(msg.channel if hasattr(msg, 'channel') else 0, sfid, 0, msg.program)\n",
    "            \n",
    "            # Render audio\n",
    "            fs.get_samples(samples)\n",
    "            \n",
    "            # Convert to 16-bit PCM and save as WAV\n",
    "            import wave\n",
    "            import struct\n",
    "            \n",
    "            # Normalize and convert to int16\n",
    "            max_val = np.abs(samples).max()\n",
    "            if max_val > 0:\n",
    "                samples = samples / max_val * 0.95  # Prevent clipping\n",
    "            samples_int16 = (samples * 32767).astype(np.int16)\n",
    "            \n",
    "            # Write WAV file\n",
    "            with wave.open(str(wav_output_path), 'wb') as wav_file:\n",
    "                wav_file.setnchannels(2)  # Stereo\n",
    "                wav_file.setsampwidth(2)  # 16-bit\n",
    "                wav_file.setframerate(int(sample_rate))\n",
    "                wav_file.writeframes(samples_int16.tobytes())\n",
    "            \n",
    "            fs.stop()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Error with fluidsynth library: {e}\")\n",
    "            print(\"   Falling back to command-line method if available...\")\n",
    "            # Don't return False yet, try command-line\n",
    "    \n",
    "    # If we get here, both methods failed\n",
    "    if not USE_FLUIDSYNTH_CMD:\n",
    "        return False\n",
    "    else:\n",
    "        return False  # Command-line already tried above\n",
    "\n",
    "print(\"‚úÖ WAV conversion function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéµ Converting MIDI to WAV using soundfont: General_MIDI_64_1.6.sf2\n",
      "============================================================\n",
      "\n",
      "‚úÖ WAV file saved: generated_midi\\generated_classical_chopin_20251103_110342.wav\n",
      "   File size: 3.70 MB\n",
      "   Sample rate: 44100 Hz\n",
      "   Soundfont: General_MIDI_64_1.6.sf2\n",
      "\n",
      "üéß You can now listen to the generated audio!\n"
     ]
    }
   ],
   "source": [
    "# Convert MIDI to WAV if soundfont is selected\n",
    "if selected_soundfont and output_path.exists():\n",
    "    print(f\"\\nüéµ Converting MIDI to WAV using soundfont: {selected_soundfont.name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate WAV filename\n",
    "    wav_filename = output_path.stem + \".wav\"\n",
    "    wav_output_path = WAV_OUTPUT_DIR / wav_filename\n",
    "    \n",
    "    # Convert\n",
    "    success = midi_to_wav(\n",
    "        midi_path=output_path,\n",
    "        soundfont_path=selected_soundfont,\n",
    "        wav_output_path=wav_output_path,\n",
    "        sample_rate=44100  # CD quality\n",
    "    )\n",
    "    \n",
    "    if success and wav_output_path.exists():\n",
    "        file_size_mb = wav_output_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"\\n‚úÖ WAV file saved: {wav_output_path}\")\n",
    "        print(f\"   File size: {file_size_mb:.2f} MB\")\n",
    "        print(f\"   Sample rate: 44100 Hz\")\n",
    "        print(f\"   Soundfont: {selected_soundfont.name}\")\n",
    "        print(f\"\\nüéß You can now listen to the generated audio!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  WAV conversion failed. MIDI file is still available at: {output_path}\")\n",
    "        print(f\"   Try installing fluidsynth or check soundfont file: {selected_soundfont}\")\n",
    "else:\n",
    "    if not selected_soundfont:\n",
    "        print(\"\\n‚ö†Ô∏è  No soundfont selected. Skipping WAV generation.\")\n",
    "        print(f\"   MIDI file is available at: {output_path}\")\n",
    "    elif not output_path.exists():\n",
    "        print(f\"\\n‚ö†Ô∏è  MIDI file not found: {output_path}\")\n",
    "        print(\"   Please run the MIDI generation cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}